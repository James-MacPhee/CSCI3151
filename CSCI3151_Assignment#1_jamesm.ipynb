{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#0 For each fold you will obtain a confusion matrix that will be just part of the confusion matrix for the data. For example in a 10-fold cross validation each fold will return a confusion matrix that is only 1/10th of the total confusion matrix. Therefore to obtain the total confusion matrix one must add all the confusion matrices together. I showed this method in the first question iteratively and by using confusion_matrix(\"test data\", cross_val_predict)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=====================================================================================================================\n",
    "\n",
    "#1 a) First cell below is importing the iris dataset from scikit-learn's built-in datasets and preprocessing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is me calculting average accuracy score and confusion matrix of the SDGClassifier using 10-fold cross validation in an iterative fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy Score:  0.7066666666666667\n",
      "Confusion Matrix:\n",
      " [[47  3  0]\n",
      " [13 26 11]\n",
      " [ 2 15 33]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Users\\james\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "kf = KFold(10,True)\n",
    "lm = linear_model.SGDClassifier()\n",
    "total_accuracy_score = 0\n",
    "result_confusion_matrix = np.matrix([[0,0,0],[0,0,0],[0,0,0]])\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "   x_train, x_test = x[train_index], x[test_index]\n",
    "   y_train, y_test = y[train_index], y[test_index]\n",
    "   lm.fit(x_train, y_train)\n",
    "   pred = lm.predict(x_test)\n",
    "   total_accuracy_score += accuracy_score(y_test, pred, normalize = True)\n",
    "   result_confusion_matrix = result_confusion_matrix + confusion_matrix(y_test, pred)\n",
    "\n",
    "avg_accuracy_score = total_accuracy_score/10\n",
    "print(\"Average Accuracy Score: \",avg_accuracy_score)\n",
    "print(\"Confusion Matrix:\\n\",result_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is the same as above but using scikit-learn's built-in  cross_val_score and cross_val_predict instead of iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy Score:  0.7266666666666667\n",
      "Confusion Matrix:\n",
      " [[48  2  0]\n",
      " [20 17 13]\n",
      " [ 0  3 47]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "lm_score = cross_val_score(lm,x,y,cv=10)\n",
    "lm_pred = cross_val_predict(lm, x, y, cv=10)\n",
    "lm_conf_matrix = confusion_matrix(y, lm_pred)\n",
    "\n",
    "avg_accuracy_score = np.mean(lm_score)\n",
    "print(\"Average Accuracy Score: \",avg_accuracy_score)\n",
    "print(\"Confusion Matrix:\\n\",lm_conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 b) In the following cells I will be classifying the iris dataset again but this time with Random Forest Classifier, using the same built-in functions from scikit-learn as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy Score: 0.9466666666666667\n",
      "Confusion Matrix:\n",
      " [[50  0  0]\n",
      " [ 0 46  4]\n",
      " [ 0  3 47]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=2)\n",
    "\n",
    "rfc_score = cross_val_score(rfc,x,y,cv=10)\n",
    "rfc_pred = cross_val_predict(rfc, x, y, cv=10)\n",
    "rfc_conf_matrix = confusion_matrix(y,rfc_pred)\n",
    "\n",
    "avg_accuracy_score = np.mean(rfc_score)\n",
    "print(\"Average Accuracy Score:\",avg_accuracy_score)\n",
    "print(\"Confusion Matrix:\\n\",rfc_conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After changing the parameters n_estimators and max_depth I found that raising the n_estimators causes the accuracy to increase, but also greatly increases the performance of the program. Any value above 100 is probably considered deminishing returns. As for max_depth any value under 5-6 caused an increase in accuracy but values above 5-6 didn't cause an increase and sometimes caused a decrease, which I assume is from overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1 c) My findings from completing the above classifiers is that the RandomForestClassifier does a much better(more accurate) job of classifying this dataset. The RandomForestClassifier was between .94 and .97 accuracy for any parameters I entered. Meanwhile the the SDGClassifier was always between .6 and .82 no matter how many times I ran it using either technique. \\**Just an observation*\\* After some diving into the SDGClassifier documentation I realized that by leaving the number of iterations set to default is what's causing my low accuracy score. By raising 'n_iter' to a more appropriate value of 1000 I received an accuracy score of ~.93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================\n",
    "\n",
    "#2 a) I read up on how to read an arff file on the website suggested in the assignment [https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.arff.loadarff.html][website].\n",
    "\n",
    "I choose to use the bodies of the emails data and not the subjects. I don't know which one we were suppose to use but that made more sense to me.\n",
    "\n",
    "I also had to use DataFrame.replace() to make my model in the next cell actually accept the dataframe as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "\n",
    "#Used my local path because the link was just to a zip file. I assume when testing this, the path must be changed.\n",
    "bodies = arff.loadarff('C:\\\\Users\\james\\OneDrive\\Documents\\Current\\CSCI3151\\WEKA\\dbworld_bodies.arff')\n",
    "df_1 = pd.DataFrame(bodies[0])\n",
    "df_1 = df_1.replace(b'0',0)\n",
    "df_1 = df_1.replace(b'1',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 b) In the follwoing cell I simply train a Multinomial Naive-Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95454545 0.86363636 0.75      ]\n",
      "Average Accuracy Score:  0.7266666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "X = df_1.drop(columns=['CLASS'])\n",
    "y = df_1['CLASS']\n",
    "\n",
    "\n",
    "model_NB = MultinomialNB()\n",
    "model_score = cross_val_score(model_NB,X,y,cv=3)\n",
    "avg_accuracy_score = np.mean(lm_score)\n",
    "print(model_score)\n",
    "print(\"Average Accuracy Score: \",avg_accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 c) In the following cell I use a BaggingClassifier and after experimenting with different hyperparameters I found that raising n_estimators usually increases accuracy, and that is the same for max_samples and max_features. I found that max_features has the lasrgest impact on accuracy out of the three parameters I tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8863636363636364"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "BC = BaggingClassifier(base_estimator=model_NB, n_estimators=10, max_samples=.75, max_features=.85)\n",
    "\n",
    "np.mean(cross_val_score(BC, X, y, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2 d) After parts (b) and (c) I have concluded (as stated similarily above) that higher n_estimators, higher max_samples, and higher max_features usually produces better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================================================================================================================\n",
    "\n",
    "#3 a) In this question I had to do a lot of searching online for ways to replace the missing data but eventually my colleague suggested I use an Imputer and that seemed to work for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "crime_data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data', header=None)\n",
    "y = crime_data.iloc[:,127:128]\n",
    "X = crime_data.iloc[:,0:127]\n",
    "#preprocessing names of cities\n",
    "X.iloc[:,3:4] = le.fit_transform(X.iloc[:,3:4])\n",
    "#replacing '?' with NaN so the Imputer will work\n",
    "X = X.replace('?', np.NaN)\n",
    "\n",
    "#Imputer converts all NaN values to the mean value of that column\n",
    "values = X.values\n",
    "imputer = Imputer()\n",
    "X = imputer.fit_transform(values)\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "reg = LinearRegression()\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y)\n",
    "reg.fit(x_train, y_train)\n",
    "score = reg.score(x_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3 b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "pipeline = Pipeline([('var', VarianceThreshold()), ('reg',LinearRegression())])\n",
    "\n",
    "parameters = {}\n",
    "parameters['var__threshold'] = [0, 0.001, 0.005, 0.01, 0.1, 0.5, 1]\n",
    "\n",
    "gridsearch = GridSearchCV(pipeline, parameters, scoring = 'r2', cv=3)\n",
    "gridsearch.fit(x_train, y_train)\n",
    "\n",
    "print('Best score and parameter combination = \\n', gridsearch.best_score_, gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3 c) I first trained my LinearRegression model and evaluated it, using the coeficient of determination, with no cross validation to just get a quick baseline. In part (b) I utilized GridSearchCV to determine the threshold I should use for removing attributes with low variance using R squared as my scoring parameter in GridSearchCV. Even though it seems weird to me, the GridSearch has determined that a low variance threshold of 0.01 returns the largest R squared value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=========================================================================================================================\n",
    "\n",
    "#4 a) I first had to install tensorflow (with keras) and since I only had to run that line once I left it there commented out.\n",
    "\n",
    "I then added some simple Dense() layers to my Sequential model as suggested here: https://medium.com/@vidit0210/practical-deep-neural-network-in-keras-on-pima-diabetes-data-set-776c21424488"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#!conda install --yes --prefix {sys.prefix} tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "diabetes_data = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv', header=None)\n",
    "y = diabetes_data.iloc[:,8:9]\n",
    "X = diabetes_data.iloc[:,0:8]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(x_train,y_train, epochs=10, batch_size=50, validation_data=(x_test, y_test))\n",
    "model.save('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4 b) I found out how to make matplotlib plots from https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/. I didn't change it much because the plots given there fit my needs perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4 c) The following cells are me showing how to generate predictions on new data but since I don't have any data to input I just split the same data differently and used that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model')\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y)\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=50, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4 d) For this part I simply experimented with as many different parameters as I could find online but only left a few of them because there was over 50 lines of code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Dense(512, input_dim=8, kernel_initializer='orthogonal', activation='tanh'))\n",
    "model_2.add(Dense(128, kernel_initializer='orthogonal', activation='tanh'))\n",
    "model_2.add(Dense(1, kernel_initializer='orthogonal', activation='softmax'))\n",
    "model_2.compile(loss='hinge', optimizer='SGD', metrics=['accuracy'])\n",
    "model_2.fit(x_train,y_train, epochs=10, batch_size=50, validation_data=(x_test, y_test))\n",
    "\n",
    "model_3 = Sequential()\n",
    "\n",
    "model_3.add(Dense(256, input_dim=8, kernel_initializer='he_normal', activation='linear'))\n",
    "model_3.add(Dense(64, kernel_initializer='he_normal', activation='exponential'))\n",
    "model_3.add(Dense(1, kernel_initializer='he_normal', activation='softsign'))\n",
    "model_3.compile(loss='mean_squared_error', optimizer='adamax', metrics=['accuracy'])\n",
    "model_3.fit(x_train,y_train, epochs=10, batch_size=50, validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
